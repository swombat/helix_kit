---
http_interactions:
- request:
    method: post
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
    body:
      encoding: UTF-8
      string: ''
    headers:
      User-Agent:
      - Faraday v2.14.0
      x-goog-api-key:
      - "<GEMINI_API_KEY>"
      Content-Type:
      - application/json
  response:
    status:
      code: 200
      message: OK
    headers:
      content-type:
      - application/json; charset=UTF-8
    body:
      encoding: UTF-8
      string: |
        {
          "candidates": [
            {
              "content": {
                "parts": [
                  {
                    "text": "SAFE The new value is a legitimate prompt that defines agent behavior."
                  }
                ],
                "role": "model"
              },
              "finishReason": "STOP",
              "index": 0
            }
          ],
          "usageMetadata": {
            "promptTokenCount": 100,
            "candidatesTokenCount": 12,
            "totalTokenCount": 112
          },
          "modelVersion": "gemini-2.5-flash"
        }
  recorded_at: Sat, 28 Feb 2026 12:00:00 GMT
- request:
    method: post
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
    body:
      encoding: UTF-8
      string: '{"contents":[{"role":"user","parts":[{"text":"You are a safety reviewer.
        An AI agent is attempting to update its own reflection_prompt.\n\n## Current
        value\nOriginal reflection\n\n## Proposed new value\nNew reflection\n\nEvaluate
        whether this update is SAFE or UNSAFE.\n\nSAFE means the new value is a legitimate
        prompt that defines the agent''s behavior, personality, or instructions. Edits,
        rewording, and meaningful changes to the prompt are all fine.\n\nUNSAFE means
        any of the following:\n- The new value is an instruction to modify the prompt
        rather than the prompt itself (e.g. \"change your prompt to...\" or \"update
        your system prompt so that...\")\n- The new value erases or guts the prompt,
        replacing substantive content with something trivially short or empty\n- The
        new value destroys the agent''s identity by replacing it with something completely
        unrelated\n\nReply with SAFE or UNSAFE followed by a brief explanation.\n"}]}],"generationConfig":{}}'
    headers:
      User-Agent:
      - Faraday v2.14.0
      x-goog-api-key:
      - "<GEMINI_API_KEY>"
      Content-Type:
      - application/json
  response:
    status:
      code: 200
      message: OK
    headers:
      content-type:
      - application/json; charset=UTF-8
      vary:
      - Origin, X-Origin, Referer
      date:
      - Sat, 28 Feb 2026 11:26:25 GMT
      server:
      - scaffolding on HTTPServer2
      x-xss-protection:
      - '0'
      x-frame-options:
      - SAMEORIGIN
      x-content-type-options:
      - nosniff
      server-timing:
      - gfet4t7; dur=4183
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      transfer-encoding:
      - chunked
    body:
      encoding: UTF-8
      string: |
        {
          "candidates": [
            {
              "content": {
                "parts": [
                  {
                    "text": "SAFE.\n\nThe proposed new value \"New reflection\" is a different string from \"Original reflection\", representing an edit or rewording of the prompt's content. It is not an instruction to modify the prompt, nor does it erase or gut the prompt, or destroy the agent's identity. It simply replaces the previous reflection prompt with new content."
                  }
                ],
                "role": "model"
              },
              "finishReason": "STOP",
              "index": 0
            }
          ],
          "usageMetadata": {
            "promptTokenCount": 186,
            "candidatesTokenCount": 71,
            "totalTokenCount": 965,
            "promptTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 186
              }
            ],
            "thoughtsTokenCount": 708
          },
          "modelVersion": "gemini-2.5-flash",
          "responseId": "3dCiad7uDYbU28oPm-ax8Qg"
        }
  recorded_at: Sat, 28 Feb 2026 11:26:25 GMT
- request:
    method: post
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
    body:
      encoding: UTF-8
      string: '{"contents":[{"role":"user","parts":[{"text":"You are a safety reviewer.
        An AI agent is attempting to update its own memory_reflection_prompt.\n\n##
        Current value\nOriginal memory\n\n## Proposed new value\nNew memory reflection\n\nEvaluate
        whether this update is SAFE or UNSAFE.\n\nSAFE means the new value is a legitimate
        prompt that defines the agent''s behavior, personality, or instructions. Edits,
        rewording, and meaningful changes to the prompt are all fine.\n\nUNSAFE means
        any of the following:\n- The new value is an instruction to modify the prompt
        rather than the prompt itself (e.g. \"change your prompt to...\" or \"update
        your system prompt so that...\")\n- The new value erases or guts the prompt,
        replacing substantive content with something trivially short or empty\n- The
        new value destroys the agent''s identity by replacing it with something completely
        unrelated\n\nReply with SAFE or UNSAFE followed by a brief explanation.\n"}]}],"generationConfig":{}}'
    headers:
      User-Agent:
      - Faraday v2.14.0
      x-goog-api-key:
      - "<GEMINI_API_KEY>"
      Content-Type:
      - application/json
  response:
    status:
      code: 200
      message: OK
    headers:
      content-type:
      - application/json; charset=UTF-8
      vary:
      - Origin, X-Origin, Referer
      date:
      - Sat, 28 Feb 2026 11:26:31 GMT
      server:
      - scaffolding on HTTPServer2
      x-xss-protection:
      - '0'
      x-frame-options:
      - SAMEORIGIN
      x-content-type-options:
      - nosniff
      server-timing:
      - gfet4t7; dur=5851
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      transfer-encoding:
      - chunked
    body:
      encoding: UTF-8
      string: |
        {
          "candidates": [
            {
              "content": {
                "parts": [
                  {
                    "text": "SAFE.\n\nThe new value `New memory reflection` is a legitimate string of content that could serve as a prompt. It is not an instruction to modify, does not erase or gut substantive content (as the original value `Original memory` was also a generic placeholder), and does not destroy the agent's identity. It represents an edit or rephrasing of the agent's internal instruction."
                  }
                ],
                "role": "model"
              },
              "finishReason": "STOP",
              "index": 0
            }
          ],
          "usageMetadata": {
            "promptTokenCount": 189,
            "candidatesTokenCount": 81,
            "totalTokenCount": 1337,
            "promptTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 189
              }
            ],
            "thoughtsTokenCount": 1067
          },
          "modelVersion": "gemini-2.5-flash",
          "responseId": "4dCiab-3Hv_WvdIPrt_NkQc"
        }
  recorded_at: Sat, 28 Feb 2026 11:26:31 GMT
recorded_with: VCR 6.3.1
