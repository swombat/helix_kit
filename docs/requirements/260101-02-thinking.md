# Extended Thinking for AI Agents

## Overview

Some AI models support "extended thinking" or "reasoning" - a mode where the model shows its internal reasoning process before providing a final answer. This capability significantly improves performance on complex tasks like coding, analysis, and multi-step reasoning.

We want agents to be able to use extended thinking when their underlying model supports it, and to display these thinking traces to users in the conversation UI.

## Models with Thinking Support

Based on testing, the following models support streaming thinking:

| Model | Provider Route | Thinking Format |
|-------|---------------|-----------------|
| Claude 3.7 Sonnet | OpenRouter (`:thinking` suffix) | `reasoning` field |
| Claude Sonnet 4 | Anthropic Direct API | `thinking` content block |
| Claude Opus 4 | Anthropic Direct API | `thinking` content block |
| Claude Opus 4.1 | Anthropic Direct API | `thinking` content block |
| Claude Opus 4.5 | Anthropic Direct API | `thinking` content block |
| GPT-5 / GPT-5.2 | OpenRouter | `reasoning` field |
| Gemini 3 Pro | OpenRouter | `reasoning` field |

**Important**: Claude 4+ models (Sonnet 4, Opus 4, Opus 4.1, Opus 4.5) do NOT expose thinking through OpenRouter. They require direct Anthropic API calls with the `thinking` parameter.

## Requirements

### 1. API Routing for Thinking

When an agent uses a Claude 4+ model with thinking enabled:
- Route the request to the Anthropic API directly (not OpenRouter)
- Include the `thinking` parameter with appropriate `budget_tokens`
- Handle the different response format (content blocks vs single content string)

For other thinking-capable models (GPT-5, Gemini 3 Pro, Claude 3.7 Sonnet):
- Continue using OpenRouter
- Extract the `reasoning` field from streaming chunks

### 2. Agent Configuration

Add a thinking toggle to the agent configuration:
- Only show the toggle for models that support thinking
- When enabled, the agent will request and capture thinking traces
- Consider a "thinking budget" setting (token limit for thinking)

### 3. Message Storage

The Message model needs to store thinking content separately:
- Add a `thinking` text column to messages
- Populate this from the API response (either `thinking` content block or `reasoning` field)
- Include thinking in the JSON attributes exposed to the frontend

### 4. Streaming Experience

Thinking should stream to the user in real-time:
- Display a "Thinking..." indicator while thinking streams
- Show the thinking content in a collapsible/expandable section
- Visually distinguish thinking from the final response (but keep it in the same message bubble)
- Continue to show the final response streaming after thinking completes

### 5. UI Display

In the conversation view:
- Show thinking in a visually distinct block (e.g., lighter background, smaller text, or collapsible section) INSIDE the message bubble, not as a separate bubble.
- Default to collapsed for all thinking traces, with the first few words of the thinking being visible.

## Technical Considerations

### Anthropic API Direct Access

For Claude 4+ thinking, use the Anthropic API directly:
- The credentials already exist at `credentials.dig(:ai, :claude, :api_token)`
- Request format requires `thinking: { type: "enabled", budget_tokens: N }`
- Response includes `content` array with `thinking` and `text` blocks
- Streaming uses `thinking_delta` and `text_delta` event types

### Response Format Differences

OpenRouter thinking (GPT-5, Gemini, Claude 3.7):
```
delta: { content: "...", reasoning: "..." }
```

Anthropic Direct thinking (Claude 4+):
```
content: [
  { type: "thinking", thinking: "..." },
  { type: "text", text: "..." }
]
```

The streaming handler needs to normalize these formats.

### Models That Don't Work

- **Grok 4 / Grok 4 Fast**: Returns encrypted `reasoning_details` - not usable
- **Claude Opus 4.5 via OpenRouter**: No thinking exposed - must use Anthropic direct

## Out of Scope

- Thinking for non-streaming responses (focus on streaming first)
- User-editable thinking budgets per-message
- Thinking for tool calls (focus on text responses first)

## Clarifications

Based on discussion with the product owner:

1. **Thinking budget**: Should be a per-agent setting (if RubyLLM supports it via `with_params`). Research shows RubyLLM has `with_params(**params)` that can pass additional API parameters. For Anthropic, this would be `thinking: { type: "enabled", budget_tokens: N }`.

2. **UI collapse behavior**: Always start collapsed. Show approximately one line of thinking content with a thought bubble icon. No user preference to remember expand/collapse state.

3. **Model detection**: Implement as a simple checkbox on the agent setup UI - "Enable thinking" - which will only be shown for models that support thinking. The model support list can be hardcoded initially.

4. **Error handling**: If thinking is enabled but the API call fails (e.g., missing/invalid Anthropic API key for Claude 4+ models), show an error message to the user. Do not silently fall back to OpenRouter without thinking.
